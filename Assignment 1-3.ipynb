
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce26696",
   "metadata": {},
   "source": [
    "Note: Use this template to develop your project. Do not change the steps. For each step, you may add additional cells if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dd1d64",
   "metadata": {},
   "source": [
    "#### Group Information\n",
    "\n",
    "Group No: Derma_2\n",
    "\n",
    "- Member 1: MOHAMAD NAZMI BIN HASHIM\n",
    "- Member 2: MIOR MUHAMMAD IRFAN BIN MIOR LATFEE\n",
    "- Member 3: MUHAMMAD HAIQAL BIN RAFIQUZZAMAN\n",
    "- Member 4: MUHAMMAD KHAWARIZMI BIN JEFRI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0239cfe9",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a04735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line serves as a configuration option for Jupyter Notebook's Jedi autocomplete library\n",
    "%config Completer.use_jedi=False\n",
    "\n",
    "# This lines imports NumPy library that is used to support effective numerical operations and arrays in Python\n",
    "import numpy as np \n",
    "\n",
    "#This line imports the Pandas library, which provides data manipulation and analysis tools in Python\n",
    "import pandas as pd\n",
    "\n",
    "# This line imports the pyplot module from the Matplotlib library, that is used create \n",
    "# various types of plots and visualizations.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba455fd5",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf67cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset to enable the data can be worked with\n",
    "# read data from a csv file\n",
    "dataset = pd.read_csv('assignment1_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23cea945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.764216</td>\n",
       "      <td>-1.016209</td>\n",
       "      <td>0.149410</td>\n",
       "      <td>-0.050119</td>\n",
       "      <td>-0.578127</td>\n",
       "      <td>6.242514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.763880</td>\n",
       "      <td>-1.159509</td>\n",
       "      <td>-0.721492</td>\n",
       "      <td>-0.654067</td>\n",
       "      <td>-0.431670</td>\n",
       "      <td>-8.118241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.519329</td>\n",
       "      <td>-0.664621</td>\n",
       "      <td>-1.694904</td>\n",
       "      <td>1.339779</td>\n",
       "      <td>0.182764</td>\n",
       "      <td>66.722455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.177388</td>\n",
       "      <td>0.515623</td>\n",
       "      <td>0.135144</td>\n",
       "      <td>-0.647634</td>\n",
       "      <td>-0.405631</td>\n",
       "      <td>-27.716793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104022</td>\n",
       "      <td>0.749665</td>\n",
       "      <td>-0.939338</td>\n",
       "      <td>-0.090725</td>\n",
       "      <td>-0.639963</td>\n",
       "      <td>8.192075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2        f3        f4        f5   response\n",
       "0 -0.764216 -1.016209  0.149410 -0.050119 -0.578127   6.242514\n",
       "1  0.763880 -1.159509 -0.721492 -0.654067 -0.431670  -8.118241\n",
       "2  0.519329 -0.664621 -1.694904  1.339779  0.182764  66.722455\n",
       "3 -0.177388  0.515623  0.135144 -0.647634 -0.405631 -27.716793\n",
       "4  0.104022  0.749665 -0.939338 -0.090725 -0.639963   8.192075"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To retrieve the data in the first five rows\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92bc349b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.310133</td>\n",
       "      <td>0.529274</td>\n",
       "      <td>-1.439255</td>\n",
       "      <td>0.724974</td>\n",
       "      <td>0.430063</td>\n",
       "      <td>35.181828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.731895</td>\n",
       "      <td>-0.223302</td>\n",
       "      <td>-1.228191</td>\n",
       "      <td>-2.034934</td>\n",
       "      <td>0.509077</td>\n",
       "      <td>-70.134876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.343181</td>\n",
       "      <td>0.431241</td>\n",
       "      <td>-0.054715</td>\n",
       "      <td>0.945423</td>\n",
       "      <td>-2.474684</td>\n",
       "      <td>42.925478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.391021</td>\n",
       "      <td>0.494147</td>\n",
       "      <td>0.106403</td>\n",
       "      <td>-0.652278</td>\n",
       "      <td>-0.200139</td>\n",
       "      <td>-13.287862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.376168</td>\n",
       "      <td>-0.054266</td>\n",
       "      <td>-0.880176</td>\n",
       "      <td>-0.334246</td>\n",
       "      <td>-0.043447</td>\n",
       "      <td>-6.829767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1        f2        f3        f4        f5   response\n",
       "995 -0.310133  0.529274 -1.439255  0.724974  0.430063  35.181828\n",
       "996 -0.731895 -0.223302 -1.228191 -2.034934  0.509077 -70.134876\n",
       "997  0.343181  0.431241 -0.054715  0.945423 -2.474684  42.925478\n",
       "998  0.391021  0.494147  0.106403 -0.652278 -0.200139 -13.287862\n",
       "999 -0.376168 -0.054266 -0.880176 -0.334246 -0.043447  -6.829767"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To retrieve the data in the last five rows\n",
    "dataset.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48d46190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.012255</td>\n",
       "      <td>-0.043030</td>\n",
       "      <td>-0.065785</td>\n",
       "      <td>0.039616</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>11.229435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.998816</td>\n",
       "      <td>1.042413</td>\n",
       "      <td>0.982640</td>\n",
       "      <td>1.023960</td>\n",
       "      <td>1.006679</td>\n",
       "      <td>40.028188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.174809</td>\n",
       "      <td>-3.381691</td>\n",
       "      <td>-3.158010</td>\n",
       "      <td>-2.764936</td>\n",
       "      <td>-2.946633</td>\n",
       "      <td>-103.044475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.655282</td>\n",
       "      <td>-0.759477</td>\n",
       "      <td>-0.734505</td>\n",
       "      <td>-0.660802</td>\n",
       "      <td>-0.685371</td>\n",
       "      <td>-16.580272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.001177</td>\n",
       "      <td>-0.038444</td>\n",
       "      <td>-0.049838</td>\n",
       "      <td>-0.006831</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>10.554227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.697331</td>\n",
       "      <td>0.696343</td>\n",
       "      <td>0.591642</td>\n",
       "      <td>0.737806</td>\n",
       "      <td>0.710398</td>\n",
       "      <td>38.485118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.092866</td>\n",
       "      <td>3.534175</td>\n",
       "      <td>3.406115</td>\n",
       "      <td>3.145835</td>\n",
       "      <td>3.007734</td>\n",
       "      <td>157.890314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                f1           f2           f3           f4           f5  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.012255    -0.043030    -0.065785     0.039616     0.008074   \n",
       "std       0.998816     1.042413     0.982640     1.023960     1.006679   \n",
       "min      -3.174809    -3.381691    -3.158010    -2.764936    -2.946633   \n",
       "25%      -0.655282    -0.759477    -0.734505    -0.660802    -0.685371   \n",
       "50%      -0.001177    -0.038444    -0.049838    -0.006831    -0.000368   \n",
       "75%       0.697331     0.696343     0.591642     0.737806     0.710398   \n",
       "max       3.092866     3.534175     3.406115     3.145835     3.007734   \n",
       "\n",
       "          response  \n",
       "count  1000.000000  \n",
       "mean     11.229435  \n",
       "std      40.028188  \n",
       "min    -103.044475  \n",
       "25%     -16.580272  \n",
       "50%      10.554227  \n",
       "75%      38.485118  \n",
       "max     157.890314  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the quick overview of the data distribution and the dain insights about dataset\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25576a90",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac2d37cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y, yhat):\n",
    "    \"\"\" Pass two arguments\n",
    "    Arguments:\n",
    "        y: responses\n",
    "        yhat: predicted value\n",
    "    Returns:\n",
    "        loss: loss value\n",
    "    \"\"\"\n",
    "    #calculate the mean squared error for the loss value\n",
    "    #loss = ((y - yhat)**2).mean()\n",
    "    \n",
    "    #calculate the mean absolute error for the loss value\n",
    "    error = yhat - y\n",
    "    absolute_error = np.absolute(error)\n",
    "    total_absolute_error = np.sum(absolute_error)\n",
    "    loss = total_absolute_error/y.size\n",
    "    \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf7a8ef",
   "metadata": {},
   "source": [
    "#### Define function to perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4d36037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w,x):\n",
    "    \"\"\" Pass two arguments\n",
    "    Arguments:\n",
    "        w: weights\n",
    "        X: input features\n",
    "    Returns:\n",
    "        yhat: predicted values\n",
    "    \"\"\"\n",
    "    \n",
    "    yhat = x.dot(w)\n",
    "   \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bb47e6",
   "metadata": {},
   "source": [
    "#### Define function for model training\n",
    "Display the training loss value for each epoch of the training loop. The displayed value must be in 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64780369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, alpha, max_epoch):\n",
    "    \"\"\" Pass four arguments\n",
    "    Arguments:\n",
    "        X: input features\n",
    "        y: responses\n",
    "        alpha: learning rate\n",
    "        max_epoch: maximum epochs\n",
    "    Returns:\n",
    "        w: estimated weights\n",
    "        hist_loss: training loss history\n",
    "    \"\"\"\n",
    "    \n",
    "    # Multivariate Linear Regression using Gradient Descent\n",
    "    n = X.shape[1] # get number of columns for X\n",
    "    w = np.ones(n) # set the number of number of weights from n\n",
    "    yhat = predict(w,X) # Calculate hypothesis using formula\n",
    "    hist_loss = []\n",
    "\n",
    "    # Gradient descent algorithm\n",
    "    hist_loss = np.ones(max_epoch)\n",
    "    for i in range (0, max_epoch):\n",
    "        w[0] = w[0] - (alpha / X.shape[0]) * sum(yhat-y)\n",
    "        for j in range(1, n) :\n",
    "            w[j] = w[j] - (alpha/ X.shape[0]) * sum((yhat-y) * X[:, j])\n",
    "        yhat = predict(w,X)\n",
    "        hist_loss[i] = loss_fn(y, yhat) #call the loss_fn function\n",
    "        print(f\"Epoch {i+1}: Loss = {hist_loss[i]:.3f}\") #display loss value for each epoch\n",
    "\n",
    "    \n",
    "\n",
    "    return w, hist_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ac3fc",
   "metadata": {},
   "source": [
    "#### Split the dataset\n",
    "The ratio of training and test is 8:2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d150f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn provides a tool called train_test_split that assists in dividing \n",
    "# a dataset into training and testing subsets. \n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6ab9fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line selects all the rows of the dataset and all columns except the last column\n",
    "X = dataset.iloc[:, :-1] #assigning features to a variable\n",
    "\n",
    "# This line selects all the rows of the dataset and only the last column\n",
    "y = dataset.iloc[:, -1]  #assigning target to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a623a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0] # number of samples =1000 rows\n",
    "ones =np.ones((m,1))\n",
    "X = np. concatenate((ones, X), axis=1) # Nuw x with X0's =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be939cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset \n",
    "# Note: Random state is used to split the same row constantly\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b50633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab48de0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train set: \n",
      "X_train set:  (800, 6) \n",
      "y_train set:  (800,)\n",
      "\n",
      "The shape of test set: \n",
      "X_test set:  (200, 6) \n",
      "y_test set:  (200,)\n"
     ]
    }
   ],
   "source": [
    "#Display number of rows and columns for the datasets\n",
    "print('The shape of train set: ')\n",
    "print('X_train set: ', X_train.shape, '\\ny_train set: ', y_train.shape)\n",
    "print('')\n",
    "print('The shape of test set: ')\n",
    "print('X_test set: ', X_test.shape, '\\ny_test set: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d5638",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55a3e316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 28.665\n",
      "Epoch 2: Loss = 25.681\n",
      "Epoch 3: Loss = 23.018\n",
      "Epoch 4: Loss = 20.645\n",
      "Epoch 5: Loss = 18.538\n",
      "Epoch 6: Loss = 16.664\n",
      "Epoch 7: Loss = 14.999\n",
      "Epoch 8: Loss = 13.522\n",
      "Epoch 9: Loss = 12.221\n",
      "Epoch 10: Loss = 11.071\n",
      "Epoch 11: Loss = 10.059\n",
      "Epoch 12: Loss = 9.164\n",
      "Epoch 13: Loss = 8.385\n",
      "Epoch 14: Loss = 7.708\n",
      "Epoch 15: Loss = 7.117\n",
      "Epoch 16: Loss = 6.605\n",
      "Epoch 17: Loss = 6.164\n",
      "Epoch 18: Loss = 5.785\n",
      "Epoch 19: Loss = 5.460\n",
      "Epoch 20: Loss = 5.189\n",
      "Epoch 21: Loss = 4.969\n",
      "Epoch 22: Loss = 4.785\n",
      "Epoch 23: Loss = 4.627\n",
      "Epoch 24: Loss = 4.494\n",
      "Epoch 25: Loss = 4.391\n",
      "Epoch 26: Loss = 4.307\n",
      "Epoch 27: Loss = 4.242\n",
      "Epoch 28: Loss = 4.187\n",
      "Epoch 29: Loss = 4.144\n",
      "Epoch 30: Loss = 4.110\n",
      "Epoch 31: Loss = 4.084\n",
      "Epoch 32: Loss = 4.064\n",
      "Epoch 33: Loss = 4.048\n",
      "Epoch 34: Loss = 4.037\n",
      "Epoch 35: Loss = 4.029\n",
      "Epoch 36: Loss = 4.024\n",
      "Epoch 37: Loss = 4.020\n",
      "Epoch 38: Loss = 4.017\n",
      "Epoch 39: Loss = 4.015\n",
      "Epoch 40: Loss = 4.014\n",
      "Epoch 41: Loss = 4.013\n",
      "Epoch 42: Loss = 4.012\n",
      "Epoch 43: Loss = 4.012\n",
      "Epoch 44: Loss = 4.012\n",
      "Epoch 45: Loss = 4.012\n",
      "Epoch 46: Loss = 4.012\n",
      "Epoch 47: Loss = 4.012\n",
      "Epoch 48: Loss = 4.012\n",
      "Epoch 49: Loss = 4.013\n",
      "Epoch 50: Loss = 4.013\n",
      "Epoch 51: Loss = 4.013\n",
      "Epoch 52: Loss = 4.014\n",
      "Epoch 53: Loss = 4.014\n",
      "Epoch 54: Loss = 4.014\n",
      "Epoch 55: Loss = 4.015\n",
      "Epoch 56: Loss = 4.015\n",
      "Epoch 57: Loss = 4.015\n",
      "Epoch 58: Loss = 4.015\n",
      "Epoch 59: Loss = 4.015\n",
      "Epoch 60: Loss = 4.016\n",
      "Epoch 61: Loss = 4.016\n",
      "Epoch 62: Loss = 4.016\n",
      "Epoch 63: Loss = 4.016\n",
      "Epoch 64: Loss = 4.016\n",
      "Epoch 65: Loss = 4.016\n",
      "Epoch 66: Loss = 4.016\n",
      "Epoch 67: Loss = 4.016\n",
      "Epoch 68: Loss = 4.016\n",
      "Epoch 69: Loss = 4.017\n",
      "Epoch 70: Loss = 4.017\n",
      "Epoch 71: Loss = 4.017\n",
      "Epoch 72: Loss = 4.017\n",
      "Epoch 73: Loss = 4.017\n",
      "Epoch 74: Loss = 4.017\n",
      "Epoch 75: Loss = 4.017\n",
      "Epoch 76: Loss = 4.017\n",
      "Epoch 77: Loss = 4.017\n",
      "Epoch 78: Loss = 4.017\n",
      "Epoch 79: Loss = 4.017\n",
      "Epoch 80: Loss = 4.017\n",
      "Epoch 81: Loss = 4.017\n",
      "Epoch 82: Loss = 4.017\n",
      "Epoch 83: Loss = 4.017\n",
      "Epoch 84: Loss = 4.017\n",
      "Epoch 85: Loss = 4.017\n",
      "Epoch 86: Loss = 4.017\n",
      "Epoch 87: Loss = 4.017\n",
      "Epoch 88: Loss = 4.017\n",
      "Epoch 89: Loss = 4.017\n",
      "Epoch 90: Loss = 4.017\n",
      "Epoch 91: Loss = 4.017\n",
      "Epoch 92: Loss = 4.017\n",
      "Epoch 93: Loss = 4.017\n",
      "Epoch 94: Loss = 4.017\n",
      "Epoch 95: Loss = 4.017\n",
      "Epoch 96: Loss = 4.017\n",
      "Epoch 97: Loss = 4.017\n",
      "Epoch 98: Loss = 4.017\n",
      "Epoch 99: Loss = 4.017\n",
      "Epoch 100: Loss = 4.017\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "max_epoch = 100\n",
    "w, hist_loss = train_model(X_train, y_train, alpha, max_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5ad9e",
   "metadata": {},
   "source": [
    "#### Display the estimated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63c6f5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated weights:\n",
      "The estimated weight of w0 is: 9.54428361814229\n",
      "The estimated weight of w1 is: 11.748065838643976\n",
      "The estimated weight of w2 is: -0.07326348667363941\n",
      "The estimated weight of w3 is: 0.10474282998248938\n",
      "The estimated weight of w4 is: 36.972189660534845\n",
      "The estimated weight of w5 is: 0.03440591685751843\n"
     ]
    }
   ],
   "source": [
    "# This section will print the estimated weight that are already calculated from train_model fuunction\n",
    "\n",
    "print(\"Estimated weights:\")\n",
    "for i, weight in enumerate(w):\n",
    "    print(f\"The estimated weight of w{i} is: {weight:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47476f87",
   "metadata": {},
   "source": [
    "#### Display the training loss against epoch graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "004eb58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss against epoch\n",
    "plt.plot(range(max_epoch), hist_loss)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8423801",
   "metadata": {},
   "source": [
    "The graph training loss against epoch shows that the trainig loss starting to decline when the number of epoch is increasing. From the observation regarding the graph above, the initial loss is the highest one because the optimization algorithm, which is gradient descent is not carried out yet at first place. After the algorithm iteratively updates the model's parameter based on the training data, the model steadily improves its predictions which lower the training loss from time to time. \n",
    "\n",
    "Basically, the gradient descent, the optimization algorithm will the find the optimal parameters that will minimize the difference between the target outputs' predicted and actual values. This goal can be achieved when the algorithm repeatedly adjusting the parameter in each epoch and manages to decrease the loss.\n",
    "\n",
    "When the number of epoch increases, the model are provided with more oppurtunities to learn and finding the best parameters from the training data. As a result, the training loss will be gradually decreases until it reaches a point where further iterations do not significantly improve the model's performance. For example, the graph above shows that the training loss started to maintain its value and there are no trend of fluctuate in the data. Based on the result above, the relationship between the number of epochs and the training loss may not always be strictly decreasing but the overall trend is typically a decline in the loss as the number of epochs increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ac2cf",
   "metadata": {},
   "source": [
    "#### Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bff3adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 4.111794879906295\n"
     ]
    }
   ],
   "source": [
    "# Calculate the test loss using the estimated weights\n",
    "yhat_test = predict(w, X_test)\n",
    "test_loss = loss_fn(y_test, yhat_test)\n",
    "print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f206de",
   "metadata": {},
   "source": [
    "#### Display the r2 score, mean squared error and mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecddf85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c05fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set R-squared: 0.9834333413966764\n",
      "Test set MSE: 27.294250357419305\n",
      "Test set MAE: 4.111794879906295\n"
     ]
    }
   ],
   "source": [
    "# Calculate the test set performance metrics\n",
    "r_squared = r2_score(y_test, yhat_test)\n",
    "mse = mean_squared_error(y_test, yhat_test)\n",
    "mae = mean_absolute_error(y_test, yhat_test)\n",
    "\n",
    "# Display the performance metrics\n",
    "print(\"Test set R-squared:\", r_squared)\n",
    "print(\"Test set MSE:\", mse)\n",
    "print(\"Test set MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thank you and have a nice day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
